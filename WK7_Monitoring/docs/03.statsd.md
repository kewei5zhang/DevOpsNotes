# Statsd

Instead of Prometheus scraping our Python web application directly, we will let each worker process push its metrics to a certain “bridge” application, which will then convert these individual data points into aggregated metrics. These aggregated metrics will then be converted into Prometheus metrics when Prometheus queries the bridge.

## Statsd Exporter

This “bridge” application here is the `statsd exporter`. The idea is that we will modify our middleware `app_helper` module to push the metrics in a [statsd] compatible format to this bridge instead:
```
[Python Web application Worker]   \

[Python Web application Worker]   - > [Statsd Exporter]    <- [Prometheus]

[Python Web application Worker]   /

```


## Hands on

Let us build our app
```
cd flask_statsd_prometheus
docker build -t jr/flask_app_statsd .
```
verify it can run

```
docker run  -ti -p 3000:3000  jr/flask_app_statsd 
```
Stop existing running dockers

```
docker rm webapp 
docker rm prometheus
```

Docker compose up now
```
docker compose -f docker-compose.yml -f docker-compose-infra.yml up
```

Hit some endpoints at `locahost:3000` and try the following query `localhost:9090/graph`
```
request_count
```

Now, you wouldn't see a problem with request count drop. 

### Optional - Mapping rules

StatsD mapping rules are used to transform and map incoming StatsD-style metrics to a format that can be understood by Prometheus

```
- match: airflow.scheduler_heartbeat
  match_type: regex
  name: "airflow_scheduler_heartbeat"
  labels:
    type: counter
```

You can then start statd passing statsd_mapping.conf to the command argument.

```
statsd_exporter:
  image: prom/statsd_exporter
  command: "-statsd.mapping-config=/tmp/statsd_mapping.conf"
  ports:
    - "9102:9102"
    - "9125:9125/udp"
  volumes:
    - "./statsd_mapping.conf:/tmp/statsd_mapping.conf"
```
